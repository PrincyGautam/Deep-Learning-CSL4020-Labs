{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install torchtext\n",
        "import torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6t_CSwpr0Zl",
        "outputId": "b4e41719-9b95-4a5f-a110-e6d805a14d69"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext) (4.64.1)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# here upload the zipped dataset folder (i.e. data.zip)"
      ],
      "metadata": {
        "id": "2pgx3RLUmId7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "w2kQxJQhmyDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb4de49-5dfc-4e93-b1da-23fb070b8877"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the directory containing the .txt files\n",
        "directory_path = r'/content/data/names'\n",
        "\n",
        "# Initialize an empty list to store the data\n",
        "data = []\n",
        "\n",
        "# Loop through each file in the directory\n",
        "for filename in os.listdir(directory_path):\n",
        "    # Get the language name from the file name (assuming file names are in the format \"language.txt\")\n",
        "    language = os.path.splitext(filename)[0]\n",
        "    # Open the file and read in each name, stripping any whitespace or newline characters\n",
        "    with open(os.path.join(directory_path, filename), \"r\") as f:\n",
        "        for line in f:\n",
        "            # Append each name along with its language to the list\n",
        "            data.append((line.strip(), language))\n",
        "\n",
        "# Convert the list to a pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=['name', 'language'])\n",
        "\n",
        "# Shuffle the DataFrame randomly\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split the DataFrame into train, validation, and test sets with an 80:10:10 split\n",
        "train, val, test = np.split(df, [int(0.8*len(df)), int(0.9*len(df))])\n",
        "\n",
        "# Print the number of examples in each set\n",
        "print(\"Number of examples in train set:\", len(train))\n",
        "print(\"Number of examples in validation set:\", len(val))\n",
        "print(\"Number of examples in test set:\", len(test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwn8kwnmnmgN",
        "outputId": "0cc690cc-f22c-4f8e-99b8-e5a5f41c0fb3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in train set: 16059\n",
            "Number of examples in validation set: 2007\n",
            "Number of examples in test set: 2008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the maximum length of the input sequence\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20"
      ],
      "metadata": {
        "id": "HFIn_sFkFiR5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and split the data into train, val, and test (80:10:10)"
      ],
      "metadata": {
        "id": "ORFNhYsHFyUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.vocab as vocab\n",
        "\n",
        "# Create a tokenizer function to split the text data into tokens\n",
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "\n",
        "# Get the text data from the training set\n",
        "train_texts = train['name'].tolist()\n",
        "\n",
        "# Create a vocabulary from the training data\n",
        "vocab_data = [tokenizer(text) for text in train_texts]\n",
        "vocab = vocab.build_vocab_from_iterator(vocab_data, specials=[\"<unk>\"])\n",
        "\n",
        "# Convert the text data to integer sequences using the vocabulary\n",
        "train_sequences = [torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long) for text in train_texts]\n",
        "\n",
        "# For the validation and test sets, replace out-of-vocabulary words with <unk>\n",
        "val_texts = [text if all(token in vocab for token in tokenizer(text)) else \"<unk>\" for text in val['name'].tolist()]\n",
        "test_texts = [text if all(token in vocab for token in tokenizer(text)) else \"<unk>\" for text in test['name'].tolist()]\n",
        "\n",
        "val_sequences = [torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long) for text in val_texts]\n",
        "test_sequences = [torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long) for text in test_texts]\n",
        "\n",
        "# Pad the sequences to have a fixed length\n",
        "train_data = torch.nn.utils.rnn.pad_sequence(train_sequences, batch_first=True, padding_value=0)\n",
        "val_data = torch.nn.utils.rnn.pad_sequence(val_sequences, batch_first=True, padding_value=0)\n",
        "test_data = torch.nn.utils.rnn.pad_sequence(test_sequences, batch_first=True, padding_value=0)\n",
        "\n",
        "# Convert the language labels to one-hot encoded vectors\n",
        "train_labels = torch.tensor(pd.get_dummies(train['language']).values)\n",
        "val_labels = torch.tensor(pd.get_dummies(val['language']).values)\n",
        "test_labels = torch.tensor(pd.get_dummies(test['language']).values)\n",
        "\n",
        "# Create PyTorch datasets and dataloaders for the train, validation, and test sets\n",
        "train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataset = torch.utils.data.TensorDataset(val_data, val_labels)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_data, test_labels)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "mvt9ot1BuMX7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN architecture"
      ],
      "metadata": {
        "id": "jfE_DzVZF9Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PyTorch dataset for the name language classification task\n",
        "class NameLanguageDataset(Dataset):\n",
        "    def __init__(self, data, labels, tokenizer):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Convert the name to a sequence of integers\n",
        "        name = self.data[index]\n",
        "        sequence = self.tokenizer.texts_to_sequences([name])[0]\n",
        "        # Pad the sequence to have a fixed length\n",
        "        padded_sequence = np.zeros(MAX_SEQUENCE_LENGTH, dtype=np.int64)\n",
        "        padded_sequence[:len(sequence)] = sequence\n",
        "        # Get the label for the name\n",
        "        label = self.labels[index]\n",
        "        return torch.tensor(padded_sequence), torch.tensor(label)\n",
        "\n",
        "# Define the RNN model architecture\n",
        "class NameLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes):\n",
        "        super(NameLanguageModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 32)\n",
        "        self.lstm = nn.LSTM(32, 64, dropout=0.2, batch_first=True)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, (h_n, c_n) = self.lstm(x)\n",
        "        x = h_n[-1, :, :]\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qwbqV1L6sPqJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device to use for training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "l5ipEYXGKUjn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new instance of the model\n",
        "model = NameLanguageModel(len(vocab), len(pd.get_dummies(df['language']).columns))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flW9yuYV8iTC",
        "outputId": "dceeb978-9fcb-46d7-a95d-18a0721384cb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NameLanguageModel(\n",
              "  (embedding): Embedding(14078, 32)\n",
              "  (lstm): LSTM(32, 64, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=64, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "QrhhBGUTywak"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train loss"
      ],
      "metadata": {
        "id": "HYWVgA_2HCPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists to store the training and validation losses\n",
        "train_losses = []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Set the model to train mode\n",
        "    model.train()\n",
        "    # Loop over the batches in the train dataloader\n",
        "    train_loss_epoch = 0.0\n",
        "    for batch in train_dataloader:\n",
        "        # Move the data to the device\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "        # Compute the loss for this batch and add it to the epoch loss\n",
        "        train_loss_epoch += loss.item()\n",
        "    # Compute the average loss per batch and append it to the train_losses list\n",
        "    train_loss_epoch /= len(train_dataloader)\n",
        "    train_losses.append(train_loss_epoch)\n",
        "\n",
        "     # Print the epoch number, training loss, and validation loss and accuracy\n",
        "    print('Epoch [%d/%d] Train Loss: %.4f' % (\n",
        "        epoch+1, NUM_EPOCHS, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEVxsbU13gGv",
        "outputId": "8bdfa175-83d6-4391-9c68-344ba7ad4e4a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Train Loss: 1.7462\n",
            "Epoch [2/20] Train Loss: 1.8438\n",
            "Epoch [3/20] Train Loss: 1.3656\n",
            "Epoch [4/20] Train Loss: 1.6057\n",
            "Epoch [5/20] Train Loss: 1.3921\n",
            "Epoch [6/20] Train Loss: 1.5509\n",
            "Epoch [7/20] Train Loss: 1.4557\n",
            "Epoch [8/20] Train Loss: 1.4266\n",
            "Epoch [9/20] Train Loss: 1.1264\n",
            "Epoch [10/20] Train Loss: 1.2861\n",
            "Epoch [11/20] Train Loss: 1.0941\n",
            "Epoch [12/20] Train Loss: 1.0360\n",
            "Epoch [13/20] Train Loss: 1.0114\n",
            "Epoch [14/20] Train Loss: 0.8809\n",
            "Epoch [15/20] Train Loss: 0.8642\n",
            "Epoch [16/20] Train Loss: 1.1115\n",
            "Epoch [17/20] Train Loss: 0.7519\n",
            "Epoch [18/20] Train Loss: 0.6819\n",
            "Epoch [19/20] Train Loss: 1.0123\n",
            "Epoch [20/20] Train Loss: 0.3518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation loss"
      ],
      "metadata": {
        "id": "BlvOFR07HE47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "val_losses = []\n",
        "val_loss = 0.0\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "val_preds = []\n",
        "val_targets = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Initialize variables to keep track of the validation loss and accuracy\n",
        "\n",
        "    \n",
        "    # Disable gradient computation to save memory\n",
        "    with torch.no_grad():\n",
        "        # Loop over the batches in the validation dataloader\n",
        "        for batch in val_dataloader:\n",
        "            # Move the data to the device\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "            # Collect the predictions and targets\n",
        "            val_preds += predicted.cpu().numpy().tolist()\n",
        "            val_targets += torch.argmax(labels, dim=1).cpu().numpy().tolist()\n",
        "\n",
        "    # Compute the validation loss and accuracy\n",
        "    val_loss /= len(val_dataset)\n",
        "    val_accuracy = val_correct / val_total\n",
        "    val_losses.append(val_loss)\n",
        "    # Print the validation loss and accuracy\n",
        "    print('Validation Loss: %.4f Validation Accuracy: %.4f' % (val_loss, val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18KPT427BgUd",
        "outputId": "32a3994e-ddbe-4820-c13f-1d313eda6323"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.9929 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n",
            "Validation Loss: 2.9944 Validation Accuracy: 0.5615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a high initial value for best validation loss\n",
        "best_val_loss = float('inf')\n",
        "# Save the best model\n",
        "if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    torch.save(model.state_dict(), 'best_model.pth')"
      ],
      "metadata": {
        "id": "kha0WuZt3qwQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved state dictionary\n",
        "state_dict = torch.load('best_model.pth', map_location=device)"
      ],
      "metadata": {
        "id": "fbZfx5wc8X3z"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epoch vs. loss curves for training and validation data"
      ],
      "metadata": {
        "id": "hFFOiL7kGNDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the epoch vs. loss curves\n",
        "plt.plot(range(1, NUM_EPOCHS+1), train_losses, label='Train')\n",
        "plt.plot(range(1, NUM_EPOCHS+1), val_losses, label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ah-BNQ1l0KiF",
        "outputId": "6e8d618b-e5df-48c6-f6fb-0f6c736da0c1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test accuracy"
      ],
      "metadata": {
        "id": "5kkFnDVzGp_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    # Loop over the batches in the test dataloader\n",
        "    for batch in test_dataloader:\n",
        "        # Move the data to the device\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "        # Compute the accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "# Compute the test loss and accuracy\n",
        "test_loss /= len(test_dataset)\n",
        "test_accuracy = test_correct / test_total\n",
        "print(\"Test Loss: %.4f Test Acc: %.4f\" % (test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Vg2yHVzlTQ",
        "outputId": "13a0b274-e3d8-499b-8545-166408dbba99"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.9688 Test Acc: 0.5657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtain a Confusion Matrix on validation data for your best model"
      ],
      "metadata": {
        "id": "JcojIoVkGVGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute and print the confusion matrix\n",
        "cm = confusion_matrix(val_targets, val_preds)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwUYn_uCCdUg",
        "outputId": "279fefea-a2ad-4f6c-e7c8-617ca56762fe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 3900     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0]\n",
            " [    0   120    20     0    40     0    20     0     0    20    20     0\n",
            "      0     0   400     0     0     0]\n",
            " [    0     0     0     0    20     0    20    20     0     0    20     0\n",
            "      0     0  1020     0     0     0]\n",
            " [    0     0     0     0    20     0    20     0     0     0    20     0\n",
            "      0     0   400     0     0     0]\n",
            " [    0   100    40     0   100    20   140    40    20    20    20     0\n",
            "      0     0  6780     0    40     0]\n",
            " [    0     0     0     0    60     0     0     0     0     0    40     0\n",
            "      0     0   540     0     0     0]\n",
            " [    0     0     0    20    60     0     0     0    20     0     0     0\n",
            "      0     0  1260     0     0     0]\n",
            " [    0     0     0     0     0     0     0    20     0     0     0     0\n",
            "      0     0   520     0     0     0]\n",
            " [    0     0     0     0    20     0     0     0    80     0     0     0\n",
            "      0     0   300     0     0     0]\n",
            " [    0     0     0     0     0    20    40     0     0    60    20     0\n",
            "      0     0  1500     0    60     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0  2120     0     0     0]\n",
            " [    0    40     0     0     0     0    20     0     0    20    20     0\n",
            "      0     0   120     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0   200     0     0     0]\n",
            " [    0     0    20     0    60     0     0     0     0    40    20     0\n",
            "      0     0    80     0     0     0]\n",
            " [    0    20     0     0    40     0     0     0    20     0    20     0\n",
            "      0     0 18260     0     0     0]\n",
            " [    0     0     0     0   180     0     0     0     0     0     0     0\n",
            "      0     0    80     0     0     0]\n",
            " [    0     0    20     0    40     0    40     0     0     0     0     0\n",
            "      0     0   500     0     0     0]\n",
            " [    0     0     0     0     0     0    20     0     0     0    20     0\n",
            "      0     0    60     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN architecture 2 (more FCs)"
      ],
      "metadata": {
        "id": "6YJgRg2FIqcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PyTorch dataset for the name language classification task\n",
        "class NameLanguageDataset(Dataset):\n",
        "    def __init__(self, data, labels, tokenizer):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Convert the name to a sequence of integers\n",
        "        name = self.data[index]\n",
        "        sequence = self.tokenizer.texts_to_sequences([name])[0]\n",
        "        # Pad the sequence to have a fixed length\n",
        "        padded_sequence = np.zeros(MAX_SEQUENCE_LENGTH, dtype=np.int64)\n",
        "        padded_sequence[:len(sequence)] = sequence\n",
        "        # Get the label for the name\n",
        "        label = self.labels[index]\n",
        "        return torch.tensor(padded_sequence), torch.tensor(label)\n",
        "\n",
        "# Define the RNN model architecture\n",
        "class NameLanguageModel2(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes):\n",
        "        super(NameLanguageModel2, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 32)\n",
        "        self.lstm = nn.LSTM(32, 64, dropout=0.2, batch_first=True)\n",
        "        self.fc1 = nn.Linear(64, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, (h_n, c_n) = self.lstm(x)\n",
        "        x = h_n[-1, :, :]\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "T25BbfQxHZmh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new instance of the model\n",
        "model2 = NameLanguageModel2(len(vocab), len(pd.get_dummies(df['language']).columns))\n",
        "model2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgsF1MMcJ66_",
        "outputId": "1f24422f-2ed5-4227-d7ba-7499f2c017ce"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NameLanguageModel2(\n",
              "  (embedding): Embedding(14078, 32)\n",
              "  (lstm): LSTM(32, 64, batch_first=True, dropout=0.2)\n",
              "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc4): Linear(in_features=32, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer2 = optim.Adam(model2.parameters())"
      ],
      "metadata": {
        "id": "0Uw3ZE3sLiqy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train loss"
      ],
      "metadata": {
        "id": "_4nNgGs5OIYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists to store the training and validation losses\n",
        "train_losses2 = []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Set the model to train mode\n",
        "    model2.train()\n",
        "    # Loop over the batches in the train dataloader\n",
        "    train_loss_epoch2 = 0.0\n",
        "    for batch in train_dataloader:\n",
        "        # Move the data to the device\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Zero the gradients\n",
        "        optimizer2.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs2 = model2(inputs)\n",
        "        loss2 = criterion(outputs2, torch.argmax(labels, dim=1))\n",
        "        # Backward pass\n",
        "        loss2.backward()\n",
        "        # Update the parameters\n",
        "        optimizer2.step()\n",
        "        # Compute the loss for this batch and add it to the epoch loss\n",
        "        train_loss_epoch2 += loss2.item()\n",
        "    # Compute the average loss per batch and append it to the train_losses list\n",
        "    train_loss_epoch2 /= len(train_dataloader)\n",
        "    train_losses2.append(train_loss_epoch2)\n",
        "\n",
        "     # Print the epoch number, training loss, and validation loss and accuracy\n",
        "    print('Epoch [%d/%d] Train Loss: %.4f' % (\n",
        "        epoch+1, NUM_EPOCHS, loss2.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNxipwpeLvVB",
        "outputId": "ba02faa6-27db-4933-e973-78eb25b2fe0a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Train Loss: 1.7935\n",
            "Epoch [2/20] Train Loss: 1.9878\n",
            "Epoch [3/20] Train Loss: 1.8495\n",
            "Epoch [4/20] Train Loss: 1.7255\n",
            "Epoch [5/20] Train Loss: 1.4657\n",
            "Epoch [6/20] Train Loss: 1.1255\n",
            "Epoch [7/20] Train Loss: 1.7896\n",
            "Epoch [8/20] Train Loss: 1.1753\n",
            "Epoch [9/20] Train Loss: 1.7203\n",
            "Epoch [10/20] Train Loss: 1.1361\n",
            "Epoch [11/20] Train Loss: 0.8751\n",
            "Epoch [12/20] Train Loss: 1.3637\n",
            "Epoch [13/20] Train Loss: 1.2385\n",
            "Epoch [14/20] Train Loss: 0.8729\n",
            "Epoch [15/20] Train Loss: 0.8634\n",
            "Epoch [16/20] Train Loss: 0.6929\n",
            "Epoch [17/20] Train Loss: 0.8246\n",
            "Epoch [18/20] Train Loss: 0.7597\n",
            "Epoch [19/20] Train Loss: 0.6267\n",
            "Epoch [20/20] Train Loss: 0.5132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation loss"
      ],
      "metadata": {
        "id": "VgjYylnBOLNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "val_losses2 = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Initialize variables to keep track of the validation loss and accuracy\n",
        "    val_loss2 = 0.0\n",
        "    val_correct2 = 0\n",
        "    val_total2 = 0\n",
        "    val_preds2 = []\n",
        "    val_targets2 = []\n",
        "    \n",
        "    # Disable gradient computation to save memory\n",
        "    with torch.no_grad():\n",
        "        # Loop over the batches in the validation dataloader\n",
        "        for batch in val_dataloader:\n",
        "            # Move the data to the device\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs2 = model2(inputs)\n",
        "            loss2 = criterion(outputs2, torch.argmax(labels, dim=1))\n",
        "            val_loss2 += loss2.item() * inputs.size(0)\n",
        "            # Compute the accuracy\n",
        "            _2, predicted2 = torch.max(outputs2.data, 1)\n",
        "            val_total2 += labels.size(0)\n",
        "            val_correct2 += (predicted2 == torch.argmax(labels, dim=1)).sum().item()\n",
        "            # Collect the predictions and targets\n",
        "            val_preds2 += predicted2.cpu().numpy().tolist()\n",
        "            val_targets2 += torch.argmax(labels, dim=1).cpu().numpy().tolist()\n",
        "\n",
        "    # Compute the validation loss and accuracy\n",
        "    val_loss2 /= len(val_dataset)\n",
        "    val_accuracy2 = val_correct2 / val_total2\n",
        "    val_losses2.append(val_loss2)\n",
        "    # Print the validation loss and accuracy\n",
        "    print('Validation Loss: %.4f Validation Accuracy: %.4f' % (val_loss2, val_accuracy2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJRDM8-0MQWq",
        "outputId": "0dc9d44c-f0f7-4436-a7ac-38cbdafa720e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n",
            "Validation Loss: 2.9041 Validation Accuracy: 0.5640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a high initial value for best validation loss\n",
        "best_val_loss2 = float('inf')\n",
        "# Save the best model\n",
        "if val_loss2 < best_val_loss2:\n",
        "    best_val_loss2 = val_loss2\n",
        "    torch.save(model2.state_dict(), 'best_model2.pth')"
      ],
      "metadata": {
        "id": "nUiotWMJNTCl"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved state dictionary\n",
        "state_dict2 = torch.load('best_model2.pth', map_location=device)"
      ],
      "metadata": {
        "id": "xbzVejt1VEoT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epoch vs. loss curves for training and validation data"
      ],
      "metadata": {
        "id": "OC5IABLbOQpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the epoch vs. loss curves\n",
        "plt.plot(range(1, NUM_EPOCHS+1), train_losses2, label='Train')\n",
        "plt.plot(range(1, NUM_EPOCHS+1), val_losses2, label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "43BXWw34Nl6z",
        "outputId": "c1fd562e-57bf-4750-eff0-4d2803394d60"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test accuracy 2"
      ],
      "metadata": {
        "id": "lANFSpPAOYl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss2 = 0.0\n",
        "test_correct2 = 0\n",
        "test_total2 = 0\n",
        "with torch.no_grad():\n",
        "    # Loop over the batches in the test dataloader\n",
        "    for batch in test_dataloader:\n",
        "        # Move the data to the device\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Forward pass\n",
        "        outputs2 = model2(inputs)\n",
        "        loss2 = criterion(outputs2, torch.argmax(labels, dim=1))\n",
        "        test_loss2 += loss2.item() * inputs.size(0)\n",
        "        # Compute the accuracy\n",
        "        _2, predicted2 = torch.max(outputs2.data, 1)\n",
        "        test_total2 += labels.size(0)\n",
        "        test_correct2 += (predicted2 == torch.argmax(labels, dim=1)).sum().item()\n",
        "# Compute the test loss and accuracy\n",
        "test_loss2 /= len(test_dataset)\n",
        "test_accuracy2 = test_correct2 / test_total2\n",
        "print(\"Test Loss: %.4f Test Acc: %.4f\" % (test_loss2, test_accuracy2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGLo5Wh_Nr2J",
        "outputId": "13a14f39-e6d8-4c98-e22b-599779e7da41"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.8779 Test Acc: 0.5637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix 2"
      ],
      "metadata": {
        "id": "UNQjVsSFObgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and print the confusion matrix\n",
        "cm2 = confusion_matrix(val_targets2, val_preds2)\n",
        "print('Confusion Matrix 2:')\n",
        "print(cm2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThybdNamN9JJ",
        "outputId": "873c16eb-c183-4f20-f7d8-7fcef245990c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix 2:\n",
            "[[195   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   3   1   0   3   0   1   0   0   3   2   0   0   0  19   0   0   0]\n",
            " [  0   0   1   0   2   0   2   0   0   1   0   0   0   0  49   0   0   0]\n",
            " [  0   0   0   0   2   0   1   0   0   0   0   0   0   0  20   0   0   0]\n",
            " [  0   4   3   0   7   0   3   0   0   6   3   0   0   0 340   0   0   0]\n",
            " [  0   0   0   0   5   0   1   0   0   0   0   0   0   0  26   0   0   0]\n",
            " [  0   0   0   0   2   0   0   0   0   1   2   0   0   0  63   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0]\n",
            " [  0   0   0   0   1   0   0   0   4   0   0   0   0   0  15   0   0   0]\n",
            " [  0   1   0   0   0   0   1   0   0   7   0   0   0   0  76   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 106   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0   0   2   1   0   0   0   6   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
            " [  0   0   0   0   3   0   0   0   0   3   1   0   0   0   4   0   0   0]\n",
            " [  0   1   1   0   0   0   0   0   0   1   0   0   0   0 915   0   0   0]\n",
            " [  0   0   1   0   7   0   0   0   0   1   0   0   0   0   4   0   0   0]\n",
            " [  0   1   0   0   3   0   0   0   0   1   0   0   0   0  25   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 RNN blocks"
      ],
      "metadata": {
        "id": "Pl2D-DXqPL0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this implementation, we have used two GRU blocks with 64 and 128 hidden units respectively. The dropout rate is set to 0.2 to prevent overfitting. The input sequences are first passed through the first GRU block, and then the output of the first block is passed through the second GRU block. The output of the second GRU block is then passed through a linear layer to get the final classification scores.\n",
        "\n",
        "To tune the hyperparameters, we can use techniques like grid search or random search. We can vary the number of hidden units, number of layers, and dropout rate to find the best configuration for our model."
      ],
      "metadata": {
        "id": "vBQ2oN29PMB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackedNameLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes):\n",
        "        super(StackedNameLanguageModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 32)\n",
        "        self.gru1 = nn.GRU(32, 64, num_layers=2, dropout=0.2, batch_first=True)\n",
        "        self.gru2 = nn.GRU(64, 128, num_layers=2, dropout=0.2, batch_first=True)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, h_n = self.gru1(x)\n",
        "        output, h_n = self.gru2(output)\n",
        "        x = h_n[-1, :, :]\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5E18UxtERDQL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new instance of the model\n",
        "model3 = StackedNameLanguageModel(len(vocab), len(pd.get_dummies(df['language']).columns))\n",
        "model3.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEvHgrBmdmxD",
        "outputId": "e2b3a2ca-e168-4f5d-cc4c-c0021bf69231"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedNameLanguageModel(\n",
              "  (embedding): Embedding(14078, 32)\n",
              "  (gru1): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (gru2): GRU(64, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer3 = optim.Adam(model3.parameters())"
      ],
      "metadata": {
        "id": "fY_-62c-dc4n"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists to store the training and validation losses\n",
        "train_losses= []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Set the model to train mode\n",
        "    model3.train()\n",
        "    # Loop over the batches in the train dataloader\n",
        "    train_loss_epoch = 0.0\n",
        "    for batch in train_dataloader:\n",
        "        # Move the data to the device\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Zero the gradients\n",
        "        optimizer3.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model3(inputs)\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update the parameters\n",
        "        optimizer3.step()\n",
        "        # Compute the loss for this batch and add it to the epoch loss\n",
        "        train_loss_epoch += loss.item()\n",
        "    # Compute the average loss per batch and append it to the train_losses list\n",
        "    train_loss_epoch /= len(train_dataloader)\n",
        "    train_losses.append(train_loss_epoch)\n",
        "\n",
        "     # Print the epoch number, training loss, and validation loss and accuracy\n",
        "    print('Epoch [%d/%d] Train Loss: %.4f' % (\n",
        "        epoch+1, NUM_EPOCHS, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcLPCyokdjz6",
        "outputId": "270c784a-2acc-41c9-9947-8cb65deb286b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Train Loss: 1.8711\n",
            "Epoch [2/20] Train Loss: 1.8074\n",
            "Epoch [3/20] Train Loss: 1.6841\n",
            "Epoch [4/20] Train Loss: 1.5319\n",
            "Epoch [5/20] Train Loss: 1.5514\n",
            "Epoch [6/20] Train Loss: 1.4098\n",
            "Epoch [7/20] Train Loss: 1.3500\n",
            "Epoch [8/20] Train Loss: 1.3760\n",
            "Epoch [9/20] Train Loss: 1.3072\n",
            "Epoch [10/20] Train Loss: 1.0281\n",
            "Epoch [11/20] Train Loss: 1.0520\n",
            "Epoch [12/20] Train Loss: 1.1652\n",
            "Epoch [13/20] Train Loss: 1.1831\n",
            "Epoch [14/20] Train Loss: 0.8611\n",
            "Epoch [15/20] Train Loss: 0.9165\n",
            "Epoch [16/20] Train Loss: 0.7330\n",
            "Epoch [17/20] Train Loss: 0.6498\n",
            "Epoch [18/20] Train Loss: 0.5667\n",
            "Epoch [19/20] Train Loss: 0.5609\n",
            "Epoch [20/20] Train Loss: 0.4941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model3.eval()\n",
        "val_losses3 = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Initialize variables to keep track of the validation loss and accuracy\n",
        "    val_loss3 = 0.0\n",
        "    val_correct3 = 0\n",
        "    val_total3 = 0\n",
        "    val_preds3 = []\n",
        "    val_targets3 = []\n",
        "    \n",
        "    # Disable gradient computation to save memory\n",
        "    with torch.no_grad():\n",
        "        # Loop over the batches in the validation dataloader\n",
        "        for batch in val_dataloader:\n",
        "            # Move the data to the device\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs3 = model3(inputs)\n",
        "            loss3 = criterion(outputs3, torch.argmax(labels, dim=1))\n",
        "            val_loss3 += loss3.item() * inputs.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted3 = torch.max(outputs3.data, 1)\n",
        "            val_total3 += labels.size(0)\n",
        "            val_correct3 += (predicted3 == torch.argmax(labels, dim=1)).sum().item()\n",
        "            # Collect the predictions and targets\n",
        "            val_preds3 += predicted3.cpu().numpy().tolist()\n",
        "            val_targets3 += torch.argmax(labels, dim=1).cpu().numpy().tolist()\n",
        "\n",
        "    # Compute the validation loss and accuracy\n",
        "    val_loss3 /= len(val_dataset)\n",
        "    val_accuracy3 = val_correct3 / val_total3\n",
        "    val_losses3.append(val_loss3)\n",
        "    # Print the validation loss and accuracy\n",
        "    print('Validation Loss: %.4f Validation Accuracy: %.4f' % (val_loss3, val_accuracy3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFn0kiCeeTbV",
        "outputId": "ce6c3d3b-6a5d-4674-b71d-8ee9a9827ea0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n",
            "Validation Loss: 2.0589 Validation Accuracy: 0.5625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a high initial value for best validation loss\n",
        "best_val_loss3 = float('inf')\n",
        "# Save the best model\n",
        "if val_loss3 < best_val_loss3:\n",
        "    best_val_loss3 = val_loss3\n",
        "    torch.save(model3.state_dict(), 'best_model3.pth')"
      ],
      "metadata": {
        "id": "CSI6XiXkW-wg"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved state dictionary\n",
        "state_dict3 = torch.load('best_model3.pth', map_location=device)"
      ],
      "metadata": {
        "id": "JdkjF_agX8gz"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.load_state_dict(state_dict3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiijoqoUYK1n",
        "outputId": "76c76859-0b70-44b3-b31d-191659be1742"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tokenizer function to split the text data into tokens\n",
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "\n",
        "# Define a function to get the language of origin for a given name\n",
        "def get_language(name):\n",
        "    # Convert the name to a sequence of integers\n",
        "    sequence = tokenizer(name)\n",
        "    sequence = [vocab[token] if token in vocab else vocab['<unk>'] for token in sequence]\n",
        "    sequence = torch.tensor(sequence, dtype=torch.long).unsqueeze(0)\n",
        "    sequence = sequence.to(device)\n",
        "    # Make a prediction using the trained model\n",
        "    with torch.no_grad():\n",
        "        output = model3(sequence)\n",
        "        prediction = torch.argmax(output).item()\n",
        "    # Get the language label for the predicted class\n",
        "    label = pd.get_dummies(df['language']).columns[prediction]\n",
        "    return label\n",
        "\n",
        "# Test the function on the given words\n",
        "words = ['Emilia', 'Alexandra', 'Sachiko', 'Vladimir', 'Minh', 'Xi', 'Muammar', 'Mukesh', 'Andrew', 'Ronaldo']\n",
        "for word in words:\n",
        "    language = get_language(word)\n",
        "    print(f\"{word}: {language}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhl7Zm5cbXoV",
        "outputId": "e6a8261b-f5a6-40fb-caab-79d0b86c6ff0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emilia: Russian\n",
            "Alexandra: Russian\n",
            "Sachiko: Russian\n",
            "Vladimir: Russian\n",
            "Minh: Russian\n",
            "Xi: Russian\n",
            "Muammar: Russian\n",
            "Mukesh: Russian\n",
            "Andrew: English\n",
            "Ronaldo: Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output from the code indicates that the trained RNN model is not able to accurately predict the language of origin for most of the input names."
      ],
      "metadata": {
        "id": "HBH26SVMZGHr"
      }
    }
  ]
}