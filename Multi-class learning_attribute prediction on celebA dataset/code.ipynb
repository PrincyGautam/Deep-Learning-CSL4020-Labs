{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65wX725GPTu7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/data/img_align_celeba.zip' -d '/content/gdrive/My Drive/data/'"
      ],
      "metadata": {
        "id": "falEcy4CU4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "JI-cffciWgZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_input = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "transform_output = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "DF3fGXORWn8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(root_dir: str, dir_name: str, file_name: str, extension: str) -> Image:\n",
        "    return Image.open(os.path.join(root_dir, dir_name, file_name))\n"
      ],
      "metadata": {
        "id": "up52w_8sSp3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, dir, transform_input, transform_output, selected_attrs):\n",
        "        super().__init__()\n",
        "        self.root = dir\n",
        "        self.selected_attrs = selected_attrs\n",
        "\n",
        "        self.transform_input = transform_input\n",
        "        self.transform_output = transform_output\n",
        "\n",
        "        # read the attributes file and create a dictionary mapping filename to the selected attributes\n",
        "        with open(os.path.join(dir, 'list_attr_celeba.txt'), 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            all_attrs = lines[1].split()\n",
        "            self.attr_dict = {}\n",
        "            for line in lines[2:]:\n",
        "                split_line = line.split()\n",
        "                filename = split_line[0]\n",
        "                attrs = (np.array(split_line[1:], dtype=int) == 1) * 2 - 1  # convert to -1 and 1\n",
        "                selected_attrs_vec = attrs[[all_attrs.index(attr) for attr in selected_attrs]]\n",
        "                self.attr_dict[filename] = selected_attrs_vec\n",
        "\n",
        "        self.list_of_inputs = list(self.attr_dict.keys())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        to_tensor_transform = transforms.ToTensor()\n",
        "\n",
        "        filename = self.list_of_inputs[idx]\n",
        "\n",
        "        input_image = load_image(self.root, 'img_align_celeba', filename, '.jpg')\n",
        "        input_image = to_tensor_transform(input_image)\n",
        "        target_attrs = torch.tensor(self.attr_dict[filename]).float()\n",
        "        \n",
        "        return input_image, target_attrs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_of_inputs)"
      ],
      "metadata": {
        "id": "JpJ3AmQGzxMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_train = 16"
      ],
      "metadata": {
        "id": "Jv5g3qZtWuQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CelebADataset(\"/content/gdrive/My Drive/data/\", transform_input=transform_input, transform_output=transform_output, \n",
        "                              selected_attrs=['Male', 'Big_Nose', 'Bags_Under_Eyes', '5_o_Clock_Shadow','Wearing_Necktie', 'Goatee', 'Sideburns', 'Bushy_Eyebrows'])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)"
      ],
      "metadata": {
        "id": "KPIm8tSyWu_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader))"
      ],
      "metadata": {
        "id": "G3SUuF3UhMeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: ', device)"
      ],
      "metadata": {
        "id": "2S8Q4r0rWyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/data/list_attr_celeba.csv.zip' -d '/content/gdrive/My Drive/data/'"
      ],
      "metadata": {
        "id": "i7B6WZCfnT7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/My Drive/data/list_attr_celeba.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "yRAatW3CnjoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('image_id', inplace = True) # Setting 'image_id' column as Index\n",
        "df.replace(to_replace = -1, value = 0,inplace = True ) # Replacing '-1' values for '0', indicating the absence of attributes in the image\n",
        "df.head(10) # Displaying dataframe after changes "
      ],
      "metadata": {
        "id": "BzrHdzShn2r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "S3Fh5gXWn6Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "hGImpbkPra4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the CelebA dataset and extract the relevant attributes\n",
        "X = df # Your data matrix of shape (num_samples, num_attributes)\n",
        "\n",
        "# Initialize the PCA object and fit the data\n",
        "pca = PCA(n_components=8) # Choose the number of principal components to keep\n",
        "pca.fit(X)\n",
        "\n",
        "# Transform the data to the new feature space\n",
        "X_pca = pca.transform(X)\n"
      ],
      "metadata": {
        "id": "7kRO1JhToBcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
        "       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
        "       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
        "       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
        "       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
        "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
        "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
        "       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
        "       'Wearing_Necklace', 'Wearing_Necktie', 'Young']"
      ],
      "metadata": {
        "id": "um-6HqESr9fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the loadings of the principal components\n",
        "loadings = pca.components_\n",
        "\n",
        "# Print the selected features\n",
        "num_components = 8 # Change this to the number of principal components you selected\n",
        "num_attributes = 40 # Change this to the number of attributes in your dataset\n",
        "\n",
        "for i in range(num_components):\n",
        "    indices = loadings[i].argsort()[::-1][:8] # Select the top 8 attributes with the highest loadings\n",
        "    features = [df.columns[j] for j in indices] # Convert the attribute indices to names\n",
        "    print(f\"Principal Component {i+1}: {features}\")\n"
      ],
      "metadata": {
        "id": "pmI2rixFoaln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top_8_attributes = ['Male', 'Big_Nose', 'Bags_Under_Eyes', '5_o_Clock_Shadow', 'Wearing_Necktie', 'Goatee', 'Sideburns', 'Bushy_Eyebrows']"
      ],
      "metadata": {
        "id": "upgQ5CgwtXn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "# Define the model architecture with a VGG16 backbone\n",
        "class AttributePredictionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = vgg16(pretrained=True).features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 8)  # Output size: number of selected attributes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Define the model and move it to the device\n",
        "model = AttributePredictionModel()\n",
        "vgg16_model = model.features\n",
        "for param in vgg16_model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "running_tasks_corrects = [0] * 8  # Initialize task-wise corrects to zero\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    for inputs, targets in tqdm(train_dataloader):\n",
        "        # Move data to device\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        total_examples += inputs.size(0)\n",
        "\n",
        "        # Compute predictions and update task-wise corrects\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        running_corrects += torch.sum(preds == targets).item()  \n",
        "        for i in range(8):\n",
        "            running_tasks_corrects[i] += torch.sum(preds[:, i] == targets[:, i]).item()\n",
        "\n",
        "    # Compute epoch statistics\n",
        "    epoch_loss = running_loss / total_examples\n",
        "    epoch_acc = running_corrects / total_examples\n",
        "    epoch_tasks_acc = [running_tasks_corrects[i] / total_examples for i in range(8)]\n",
        "\n",
        "    # Print epoch statistics\n",
        "    print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f}')\n",
        "    for i, attr in enumerate(['Male', 'Big_Nose', 'Bags_Under_Eyes', '5_o_Clock_Shadow', 'Wearing_Necktie', 'Goatee', 'Sideburns', 'Bushy_Eyebrows']):\n",
        "        print(f'\\t{attr}: {epoch_tasks_acc[i]:.4f}')\n",
        "\n",
        "overall_accuracy = 100 * running_corrects / total_examples\n",
        "print('Overall Accuracy: {:.2f}%'.format(overall_accuracy))"
      ],
      "metadata": {
        "id": "sjOw2K07xJ9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}